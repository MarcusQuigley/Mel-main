{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgYXyw1F8YxD"
      },
      "source": [
        "# ***An Exploratory Analysis of Rat Sightings In NYCs 5 Boroughs:***\n",
        "\n",
        " Creation of sets for further EDA\n",
        "Preliminary: *Are the reports of rats equally distributed throughout the boroughs?*\n",
        "\n",
        ">> Does one borough have more reports of rats per population than the other?\n",
        "where are the most reports by year, month....\n",
        "\n",
        ">>\n",
        "\n",
        "Is there a correlation between the frequency of DSNY collection and the affect on the number of sightings?\n",
        "\n",
        "Types of collections and the reported sightings.\n",
        "\n",
        "sightings to frequency\n",
        "sightings to population\n",
        "\n",
        "\n",
        "\n",
        "Possible Further exploration into:\n",
        "\n",
        ">Sightings to vendor\n",
        "\n",
        "Litter baskets.\n",
        "\n",
        ">Refuge stats compared to US\n",
        "\n",
        ">Employment stats and truck violations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRjow12GDyFI"
      },
      "source": [
        "#Reported Sightings\n",
        "---Original data sourced from:\n",
        "\n",
        " https://data.cityofnewyork.us/Social-Services/Rat-Sightings/3q43-55fe\n",
        "\n",
        "\n",
        "> *additional sources added upon completion of ReadMe.txt master repository creation*\n",
        "\n",
        "\n",
        "###Initial files joined/cleaned with Tableau Prep\n",
        "\n",
        "==> step1_ratsightings = (Modified_Zip_Code_Tabulation_Areas__MODZCTA_.csv\n",
        "Rat_Sightings.csv)\n",
        "\n",
        "\n",
        "==> dsny_frequency = (DSNY_Districts, DSNY_Frequencies, NYC_Community_Board_dist,Modified_Zip_Code_Tabulation_Areas__MODZCTA_.csv)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75PrdzzmeYfG"
      },
      "source": [
        "Neighborhoods to zips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFJ9SELregJD"
      },
      "source": [
        "* Bronx Central Bronx 10453, 10457, 10460\n",
        "* Bronx Park and Fordham 10458, 10467, 10468\n",
        "* High Bridge and Morrisania 10451, 10452, 10456\n",
        "* Hunts Point and Mott Haven 10454, 10455, 10459, 10474\n",
        "* Kingsbridge and Riverdale 10463, 10471\n",
        "* Northeast Bronx 10466, 10469, 10470, 10475\n",
        "* Brooklyn Central Brooklyn 11212, 11213, 11216, 11233, 11238\n",
        "* Southwest Brooklyn 11209, 11214, 11228\n",
        "* Borough Park 11204, 11218, 11219, 11230\n",
        "* Canarsie and Flatlands 11234, 11236, 11239\n",
        "* Southern Brooklyn 11223, 11224, 11229, 11235\n",
        "* Northwest Brooklyn 11201, 11205, 11215, 11217, 11231\n",
        "* Flatbush 11203, 11210, 11225, 11226\n",
        "* East New York and New Lots 11207, 11208\n",
        "* Greenpoint 11211, 11222\n",
        "* Sunset Park 11220, 11232\n",
        "* Bushwick and Williamsburg 11206, 11221, 11237\n",
        "* Manhattan Central Harlem 10026, 10027, 10030, 10037, 10039\n",
        "* Chelsea and Clinton 10001, 10011, 10018, 10019, 10020, 10036\n",
        "* East Harlem 10029, 10035\n",
        "* Gramercy Park and Murray Hill 10010, 10016, 10017, 10022\n",
        "* Greenwich Village and Soho 10012, 10013, 10014\n",
        "* Lower Manhattan 10004, 10005, 10006, 10007, 10038, 10280\n",
        "* Lower East Side 10002, 10003, 10009\n",
        "* Upper East Side 10021, 10028, 10044, 10065, 10075, 10128\n",
        "* Upper West Side 10023, 10024, 10025\n",
        "* Inwood and Washington Heights 10031, 10032, 10033, 10034, 10040\n",
        "* Queens Northeast Queens 11361, 11362, 11363, 11364\n",
        "* North Queens 11354, 11355, 11356, 11357, 11358, 11359, 11360\n",
        "* Central Queens 11365, 11366, 11367\n",
        "* Jamaica 11412, 11423, 11432, 11433, 11434, 11435, 11436\n",
        "* Northwest Queens 11101, 11102, 11103, 11104, 11105, 11106\n",
        "* West Central Queens 11374, 11375, 11379, 11385\n",
        "* Rockaways 11691, 11692, 11693, 11694, 11695, 11697\n",
        "* Southeast Queens 11004, 11005, 11411, 11413, 11422, 11426, 11427, 11428, 11429\n",
        "* Southwest Queens 11414, 11415, 11416, 11417, 11418, 11419, 11420, 11421\n",
        "* West Queens 11368, 11369, 11370, 11372, 11373, 11377, 11378\n",
        "* Staten Island Port Richmond 10302, 10303, 10310\n",
        "* South Shore 10306, 10307, 10308, 10309, 10312\n",
        "* Stapleton and St. George 10301, 10304, 10305\n",
        "* Mid-Island 10314"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrSI7ayL5mNC"
      },
      "source": [
        "**series count weekday**\n",
        "Monday = 0\n",
        "\n",
        "Tuesday = 1\n",
        "\n",
        "Wednesday = 2, and so on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8YT7yhvwO5s"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOoWCp4PxaiS",
        "outputId": "286f8b45-0016-4aae-a132-fc6b167027f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.4.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.0)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2023.5.7)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.4)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install geopandas\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import re # flexable way to search for matching text in strings Regular Expressions\n",
        "import seaborn as sns # plotting and graphing, built upon the matplotlib library.\n",
        "import matplotlib.pyplot as plt\n",
        "# example of a normalization\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#import geopy #ploting by location longitude and latitude\n",
        "from math import pi\n",
        "#from geopy.geocoders import Nominatim as nm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "# #these populated on their own\n",
        "# from zmq.constants import THREAD_NAME_PREFIX\n",
        "# from pandas.core.groupby import groupby\n",
        "\n",
        "# #additional imports from notebook reference\n",
        "# import plotly as ply\n",
        "# import plotly.express as px\n",
        "# import plotly.io as pio\n",
        "# import scipy as sc\n",
        "# import sympy as sy\n",
        "# import matplotlib as matplot\n",
        "# import statistics as stat\n",
        "### some imports are yet to be used...cleaning up and still exploring past analysis usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxojoVAFlrvn",
        "outputId": "84b9e5dc-9664-45e8-9947-0700095acb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwpuucdHxqUa"
      },
      "outputs": [],
      "source": [
        "# Read the csv(s)\n",
        "\n",
        "missing_values=['nan','-', '']\n",
        "rats = pd.read_csv('/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/step1_ratsightings.csv', na_values = missing_values)\n",
        "dsny = pd.read_csv('/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/dsny_frequency.csv', na_values = missing_values)\n",
        "#Unique Key as Index (after import check for duplicates then index unique key after sort of key and created date.)\n",
        "#drop false leaves the index columns in when reindexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGP4MZKwSJm"
      },
      "source": [
        "#EDA DSNY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TIJQVCv_Cvk"
      },
      "outputs": [],
      "source": [
        "print('Info:', dsny.info())\n",
        "print('top 5 rows:', dsny.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gDPtK1vGcIB"
      },
      "outputs": [],
      "source": [
        "print('Rows, Columns:', dsny.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz65D50vs9wR"
      },
      "source": [
        "##Cleaning DSNY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYOgsYecrYYj"
      },
      "outputs": [],
      "source": [
        "dsny1 = dsny.drop_duplicates()\n",
        "dsny1.shape == dsny.shape #(80475, 24)  (80481, 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3qk3pXctzqK"
      },
      "outputs": [],
      "source": [
        "dsny1.sort_values(by=['schedulecode','modzcta', 'post_code']).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQmZSovnvH68"
      },
      "outputs": [],
      "source": [
        "dsny1_sorted = pd.DataFrame(dsny1.sort_values(by=['schedulecode','modzcta', 'post_code'], ascending=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRqfWwQZwJur"
      },
      "outputs": [],
      "source": [
        "dsny1 = dsny1_sorted.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeKrWyQ8rxCP"
      },
      "outputs": [],
      "source": [
        "# check missing values in different columns via heatmap\n",
        "sns.heatmap(dsny1.isnull(), cbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTQu-hkxVlPo"
      },
      "outputs": [],
      "source": [
        "dsny1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2-Akqp9UZSr"
      },
      "outputs": [],
      "source": [
        "dsny1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjez_x_gDUcj"
      },
      "outputs": [],
      "source": [
        "dsny.bulk_day1.unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'location' column using latitude and longitude columns\n",
        "dsny1['location'] = '(' + dsny1['Latitude'].astype(str) + ', ' + dsny1['Longitude'].astype(str) + ')'\n"
      ],
      "metadata": {
        "id": "znAN532ma-t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsny1['location'].unique()"
      ],
      "metadata": {
        "id": "cCmKSGZzaRgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9hTklBz_H5k"
      },
      "source": [
        "#EDA RATS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqOVrdFF-0L7"
      },
      "outputs": [],
      "source": [
        "print('Info:', rats.info())\n",
        "print('top 5 rows:', rats.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzTQoOqs1jnJ"
      },
      "outputs": [],
      "source": [
        "print('Rows, Columns:', rats.shape)\n",
        "#80481, 25 without Unique Key as Index Rows, Columns: (208789, 28 ratsightings...no change in names or dropped collumns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a46onfw6CBh"
      },
      "source": [
        "Replacing the double checks(null)s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnHcQNoUZpRP"
      },
      "outputs": [],
      "source": [
        "rats.index.is_unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEhkQCcUpw-n"
      },
      "outputs": [],
      "source": [
        "rats.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON3PCUMVi3g-"
      },
      "outputs": [],
      "source": [
        "rats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW3lJudU0t-f"
      },
      "outputs": [],
      "source": [
        "#check min max report dates\n",
        "min_date = min(rats['created_date'])\n",
        "max_date = max(rats['created_date'])\n",
        "print('Date range: ', min_date, ' - ', max_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m3B1njiP8YO"
      },
      "outputs": [],
      "source": [
        " #check min max report dates\n",
        "# min_date = min(rats['closed_date'])\n",
        "# max_date = max(rats['closed_date'])\n",
        "# print('Date range: ', min_date, ' - ', max_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuUm8TOeJzsG"
      },
      "source": [
        "cant get index to stay... or is it me? reindex keeping this column that is sorted?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auRzO53kvXjo"
      },
      "outputs": [],
      "source": [
        "rats.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Ab5Pbas4Rv"
      },
      "source": [
        "the dates still shows as objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyLZ8_uD6vpp"
      },
      "outputs": [],
      "source": [
        "rats.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vuMrmowZOaO"
      },
      "outputs": [],
      "source": [
        "#checking the index again no sort going up to reindex nesscisary?\n",
        "rats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01oX8uDXiE_z"
      },
      "outputs": [],
      "source": [
        "rats['incident_zip'].nlargest(n=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqWRisB8wG3L"
      },
      "source": [
        "##Cleaning Rats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8CxyFskjyIo"
      },
      "outputs": [],
      "source": [
        "rats.sort_values(by=['incident_zip']).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZVoXR8MiE09"
      },
      "outputs": [],
      "source": [
        "rats_sorted = rats.sort_values(by=['created_date'], ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RfIw5q0Iptl"
      },
      "outputs": [],
      "source": [
        "rats_sorted.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwLE00vWBvFM"
      },
      "outputs": [],
      "source": [
        "print('Borough Value counts after dropping columns and nulls:/n',rats_sorted['borough'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiHn8PiE_27z"
      },
      "outputs": [],
      "source": [
        "rats_sorted.loc[~rats_sorted.index.duplicated(), :].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZN8gjhNlFbv"
      },
      "source": [
        "### Dropping duplicates/ columns/ nulls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-6q7OvV_Wr6"
      },
      "outputs": [],
      "source": [
        "rat1 = rats_sorted.drop_duplicates()\n",
        "rat1.shape == rats_sorted.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48DnC_gAdnXq"
      },
      "outputs": [],
      "source": [
        "rat1 = pd.DataFrame(rat1.sort_values(['created_date','unique_key'], ascending=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rtZNF0pJQUH"
      },
      "outputs": [],
      "source": [
        "\n",
        "#dropping columns that are unneeded or too many null values\n",
        "# rat1 = rat1.drop(['cities_acceptable_irs', 'irs_estimated_population', 'landmark', 'marg_error'], axis=1)\n",
        "# check missing values in different columns via heatmap\n",
        "# sns.heatmap(rat1.isnull(), cbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZvOkBOuI8t6"
      },
      "outputs": [],
      "source": [
        "rat1.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2zMeTs6DB-"
      },
      "source": [
        "### replacing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nao3_XXduXPf"
      },
      "outputs": [],
      "source": [
        "# Check if values in 'street_name' column are unique\n",
        "is_unique = rat1['street_name'].is_unique\n",
        "print(\"Are the values in 'street_name' column unique? \", is_unique)\n",
        "\n",
        "# Get value counts of each unique value in 'street_name' column\n",
        "street_name_counts = rat1['street_name'].value_counts()\n",
        "print(\"Value counts of 'street_name' column:\")\n",
        "print(street_name_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE_hzPLTvLRk"
      },
      "outputs": [],
      "source": [
        "# #when visualizing i noticed west had a double space and n, s, w, e was used along with north, south, east and west\n",
        "# street_west_counts = rat1[rat1['street_name'].fillna('').str.contains('west', case=False)]['street_name'].value_counts()\n",
        "# print(street_west_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAOp74_h6Ptp"
      },
      "outputs": [],
      "source": [
        "#dictionary\n",
        "street_name_replacements = {\n",
        "    r'\\bST\\b': 'STREET',\n",
        "    r'\\bAVE\\b': 'AVENUE',\n",
        "    r'\\b(BLVD|BLV)\\b': 'BOULEVARD',\n",
        "    r'\\bPL\\b': 'PLACE',\n",
        "    r'\\bCT\\b': 'COURT',\n",
        "    r'\\bDR\\b': 'DRIVE',\n",
        "    r'\\bSQ\\b': 'SQUARE',\n",
        "    r'\\bTCE\\b': 'TERRACE',\n",
        "    r'\\bAVE\\b': 'AVENUE',\n",
        "    r'\\bE\\b': 'EAST',\n",
        "    r'\\bW\\b': 'WEST',\n",
        "    r'\\bN\\b': 'NORTH',\n",
        "    r'\\bS\\b': 'SOUTH',\n",
        "    'DR MARTIN L KING JR BOULEVARD': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    'DR M L KING JR BOULEVARD': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    'DR MARTIN L KING JR BLVD': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    'DR MARTIN LUTHER KING JR BLVD': 'DR MARTIN LUTHER KING JR BOULEVARD'\n",
        "}\n",
        "\n",
        "# Apply the replacement rules\n",
        "rat1['street_name'] = rat1['street_name'].replace(street_name_replacements, regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1jt5EVS6-9z"
      },
      "outputs": [],
      "source": [
        "# rat1['street_name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN4zmmkc338a"
      },
      "outputs": [],
      "source": [
        "#dictionary\n",
        "incident_address_replacements = {\n",
        "    r'\\bST\\b': 'STREET',\n",
        "    r'\\bAVE\\b': 'AVENUE',\n",
        "    r'\\b(BLVD|BLV)\\b': 'BOULEVARD',\n",
        "    r'\\bPL\\b': 'PLACE',\n",
        "    r'\\bCT\\b': 'COURT',\n",
        "    r'\\bDR\\b': 'DRIVE',\n",
        "    r'\\bSQ\\b': 'SQUARE',\n",
        "    r'\\bTCE\\b': 'TERRACE',\n",
        "    r'\\bAVE\\b': 'AVENUE',\n",
        "    r'\\bE\\b': 'EAST',\n",
        "    r'\\bW\\b': 'WEST',\n",
        "    r'\\bN\\b': 'NORTH',\n",
        "    r'\\bS\\b': 'SOUTH',\n",
        "    r'\\bDR MARTIN L KING JR BOULEVARD\\b': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    r'\\bDR M L KING JR BOULEVARD\\b': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    r'\\bDR MARTIN L KING JR BLVD\\b': 'DR MARTIN LUTHER KING JR BOULEVARD',\n",
        "    r'\\bDR MARTIN LUTHER KING JR BLVD\\b': 'DR MARTIN LUTHER KING JR BOULEVARD'\n",
        "}\n",
        "\n",
        "# Apply the replacement rules\n",
        "rat1['incident_address'] = rat1['incident_address'].replace(incident_address_replacements, regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2WbGcwjFyC_"
      },
      "outputs": [],
      "source": [
        "# # double check if values are unique\n",
        "# is_unique = rat1['incident_address'].is_unique\n",
        "# print(\"Are the values in 'incident_address' column unique? \", is_unique)\n",
        "\n",
        "# # Get value counts of each unique value\n",
        "# value_counts = rat1['incident_address'].value_counts()\n",
        "# print(\"Value counts of 'incident_address' column:\")\n",
        "# print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkNkTlzQr7ed"
      },
      "outputs": [],
      "source": [
        "#Remove extra spaces\n",
        "rat1['incident_address'] = rat1['incident_address'].apply(lambda x: \"\".join([x[i] for i in range(len(x)) if i == 0 or (x[i] != \" \" or x[i-1] != \" \")]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srIHXhWswdfX"
      },
      "outputs": [],
      "source": [
        "address_counts = rat1['incident_address'].fillna('').value_counts()\n",
        "print(address_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grRiomke9B_g"
      },
      "outputs": [],
      "source": [
        "# Convert \"incident_zip\" to string type\n",
        "rat1['incident_zips'] = rat1['incident_zip'].astype(str)\n",
        "\n",
        "# Create a new column combining \"incident_address\" and \"incident_zip\"\n",
        "rat1['address_zip'] = rat1['incident_address'] + ', ' + rat1['incident_zips']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###New Columns"
      ],
      "metadata": {
        "id": "5a_ac9bD9N4v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJlzrzJxxn6Q"
      },
      "source": [
        "####pd.datetime/ created YQMWD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDrdO9POhQ1p"
      },
      "outputs": [],
      "source": [
        "#Converting the date column to its specified data type\n",
        "rat1['created_date'] = pd.to_datetime(rat1['created_date'])\n",
        "rat1['closed_date'] = pd.to_datetime(rat1['closed_date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ooCE9wv8dsf"
      },
      "outputs": [],
      "source": [
        "# Creating 4 new columns for easy querying\n",
        "rat1['year']= rat1.created_date.dt.year\n",
        "rat1['quarter']= rat1.created_date.dt.quarter\n",
        "rat1['month'] = rat1.created_date.dt.month\n",
        "rat1['weekday'] = rat1.created_date.dt.weekday\n",
        "rat1['day'] = rat1.created_date.dt.day\n",
        "rat1['hour'] = rat1.created_date.dt.hour\n",
        "rat1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rat1['sightings_count'] = 1"
      ],
      "metadata": {
        "id": "OkMr5feQJbIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1['sightings_count'].unique()"
      ],
      "metadata": {
        "id": "WVbzFJOGROVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1['unique_key'].isnull().sum()"
      ],
      "metadata": {
        "id": "Di55YjKcSFL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population = rat1['pop_est']\n",
        "sightings_count = rat1['sightings_count']\n",
        "\n",
        "sightings_per_capita = np.where(population != 0, sightings_count / population, 0)\n",
        "\n",
        "# Add the 'sightings_per_capita' column to the DataFrame\n",
        "rat1['sightings_per_capita'] = sightings_per_capita"
      ],
      "metadata": {
        "id": "IWS3e8FjI2vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CB_address_zip Normalized/pop_est"
      ],
      "metadata": {
        "id": "DBeeOg6ZPriF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TI3jIzpkR18"
      },
      "source": [
        "####DATEDIF = NEW COLUMN DURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ch9-iuVkWnQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Converting the date column to its specified data type\n",
        "rat1['create_date'] = pd.to_datetime(rat1['created_date'], errors='coerce').dt.date\n",
        "rat1['close_date'] = pd.to_datetime(rat1['closed_date'], errors='coerce').dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeTmOhK2NbPC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate the duration between 'create_date' and 'close_date' and assign it to 'duration' column\n",
        "rat1['duration'] = rat1['close_date'] - rat1['create_date']\n",
        "\n",
        "# Replace NaT values in 'duration' column with zeros\n",
        "rat1['duration'] = rat1['duration'].fillna(pd.Timedelta(0))\n",
        "\n",
        "# Convert duration from timedelta to integer (number of days)\n",
        "rat1['duration'] = rat1['duration'].dt.days\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(rat1.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "found_values = rat1[rat1['closed_date'] == '1899-12-31 19:00:00']\n",
        "print(found_values)"
      ],
      "metadata": {
        "id": "1vWoFC6fuG4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHaSPSdDaGUW"
      },
      "outputs": [],
      "source": [
        "rat1['duration'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rat1['frequency_cb'] = rat1['address_zip'].map(rat1['address_zip'].value_counts()).fillna(0)\n",
        "print(rat1.frequency_cb.unique())"
      ],
      "metadata": {
        "id": "m9pABXL06k5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82stBIO9JTY-"
      },
      "source": [
        "###Dropping final nulls for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0zrjvrZJejJ"
      },
      "outputs": [],
      "source": [
        "rat1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18PQbzzprx_5"
      },
      "outputs": [],
      "source": [
        "# drop duplicate data (== gives the boolean value)\n",
        "rat2 = rat1.drop_duplicates()\n",
        "rat2.shape == rat1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K1b87ipqxMR"
      },
      "source": [
        "#VALUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26fVVgZ0NQpu"
      },
      "source": [
        "####DATE RANGE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5OebHX3fBQL"
      },
      "outputs": [],
      "source": [
        "#check min max crash dates\n",
        "min_date = min(rat1['created_date'])\n",
        "max_date = max(rat1['created_date'])\n",
        "print(f'Date range:  {min_date}  -  {max_date}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '0000-00-00 00:00:00' with NaT (Not-a-Time)\n",
        "rat1['close_date'] = rat1['closed_date'].replace('0000-00-00 00:00:00', pd.NaT)\n",
        "\n",
        "# Convert 'closed_date' to datetime type\n",
        "rat1['close_date'] = pd.to_datetime(rat1['close_date'], errors='coerce')\n",
        "\n",
        "# Calculate the minimum and maximum values for 'closed_date'\n",
        "close_dates_min = rat1['close_date'].min()\n",
        "close_dates_max = rat1['close_date'].max()\n",
        "\n",
        "# Print the calculated values\n",
        "print(f\"Close Date Range: {close_dates_min} - {close_dates_max}\")"
      ],
      "metadata": {
        "id": "kXNLGoa0sjPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsUc7BsKRb4y"
      },
      "outputs": [],
      "source": [
        "#check min max crash dates\n",
        "min_date = min(rat1['closed_date'])\n",
        "max_date = max(rat1['closed_date'])\n",
        "print(f'Date range:  {min_date}  -  {max_date}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####rat1_normalized"
      ],
      "metadata": {
        "id": "Eb71RYaQTowb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rat1.columns"
      ],
      "metadata": {
        "id": "2Yh4XD4OhVFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1['create_date']"
      ],
      "metadata": {
        "id": "eo4G3Wf2q31L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'close_date' to datetime type\n",
        "rat1['close_date'] = pd.to_datetime(rat1['close_date'])\n",
        "\n",
        "# Calculate the minimum and maximum values for 'close_date'\n",
        "close_dates_min = rat1['close_date'].min()\n",
        "close_dates_max = rat1['close_date'].max()\n",
        "\n",
        "# Print the calculated values\n",
        "print(f\"Close Date Range: {close_dates_min} - {close_dates_max}\")"
      ],
      "metadata": {
        "id": "iFmS3rEFql2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1"
      ],
      "metadata": {
        "id": "ZVe1HjidSroM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v4KRvks2lhp"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.scatterplot(data=rat1, x='longitude', y='latitude', hue='community_board', alpha=0.15, palette=\"viridis\", label='Rat Sightings\\n Community Districts', ax=ax)\n",
        "sns.scatterplot(data=dsny1, x='Longitude', y='Latitude', hue= 'district', palette=\"Blues\" ,label='\\nDSNY Districts', ax=ax)\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=6, ncol=2)\n",
        "ax.set_title('Rat Sightings by Community Districts/DSNY Districts 2010-6/2023')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9efwQLyVbrr"
      },
      "source": [
        "####Top ADDRESS_ZIP incidents =  rat1.groupby(['XXX'])['address_zip'].apply(lambda x: x.value_counts().nlargest())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeLZnrd1VJUZ"
      },
      "source": [
        "Top Incidents Broken down by Created Date, Year, Quarter,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X203QFuQaGCn"
      },
      "outputs": [],
      "source": [
        "# Top addresses ZIP codes by created date\n",
        "top_addresses_by_created_date = rat1.groupby(['created_date'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "\n",
        "# Top addresses ZIP codes by year\n",
        "top_addresses_by_year = rat1.groupby(['year'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "# Top addresses ZIP codes by quarter\n",
        "top_addresses_by_quarter = rat1.groupby(['quarter'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "\n",
        "# Top addresses ZIP codes by month\n",
        "top_addresses_by_month = rat1.groupby(['month'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "# Top addresses ZIP codes by weekday\n",
        "top_addresses_by_weekday = rat1.groupby(['weekday'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "\n",
        "# Top addresses ZIP codes by day of the week\n",
        "top_addresses_by_day_of_week = rat1.groupby(['day'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "\n",
        "# Top addresses ZIP codes by hour\n",
        "top_addresses_by_hour = rat1.groupby(['hour'])['address_zip'].apply(lambda x: x.value_counts().nlargest())\n",
        "\n",
        "# Display the results\n",
        "print(\"Top addresses ZIP code by created date:\")\n",
        "print(top_addresses_by_created_date)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by year:\")\n",
        "print(top_addresses_by_year)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by quarter:\")\n",
        "print(top_addresses_by_quarter)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by month:\")\n",
        "print(top_addresses_by_month)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by weekday:\")\n",
        "print(top_addresses_by_weekday)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by day of the week:\")\n",
        "print(top_addresses_by_day_of_week)\n",
        "print()\n",
        "\n",
        "print(\"Top addresses ZIP code by hour:\")\n",
        "print(top_addresses_by_hour)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "top_addresses_by_year.plot(kind='line', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top Addresses ZIP Codes by Year')\n",
        "plt.xticks(rotation=45)"
      ],
      "metadata": {
        "id": "AyfzE5eXJh8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(top_addresses_by_month.unstack().fillna(0), cmap='coolwarm', annot=True)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('ZIP Code')\n",
        "plt.title('Top Addresses ZIP Codes by Month')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cu0FdeSSJt6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the series to a DataFrame\n",
        "df_top_addresses = pd.DataFrame(top_addresses_by_created_date)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "df_top_addresses.reset_index(inplace=True)\n",
        "\n",
        "# Rename the columns\n",
        "df_top_addresses.columns = ['created_date', 'address_zip', 'count']\n",
        "\n",
        "# Convert the 'created_date' column to a period type representing month and year\n",
        "df_top_addresses['created_date'] = pd.to_datetime(df_top_addresses['created_date'])\n",
        "df_top_addresses['month_year'] = df_top_addresses['created_date'].dt.to_period('M')\n",
        "\n",
        "# Filter the data for the last 5 years\n",
        "current_year = pd.to_datetime('today').year\n",
        "five_years_ago = current_year - 5\n",
        "df_top_addresses = df_top_addresses[df_top_addresses['created_date'].dt.year >= five_years_ago]\n",
        "\n",
        "# Get the top 3 ZIP codes per month\n",
        "top_3_per_month = df_top_addresses.groupby('month_year').apply(lambda x: x.nlargest(1, 'count')).reset_index(drop=True)\n",
        "\n",
        "# Create a figure and axes with a wider plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot the data\n",
        "top_3_per_month.groupby('month_year').apply(lambda x: plt.bar(x['address_zip'], x['count'], alpha=0.7))\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_xlabel('ZIP Code')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Top Addresses ZIP Codes per Month (Last 5 Years)')\n",
        "\n",
        "# Rotate the x-axis labels for better readability (optional)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJyyxm-eSfBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-hY684XMpB"
      },
      "source": [
        "####Top Community Board = rat1.groupby(['XXX', 'community_board']).size().reset_index(name='cb_count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8EIFdOGV6Np"
      },
      "source": [
        "#####Top Community board by created date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xXbNRxIZcCB"
      },
      "outputs": [],
      "source": [
        "# Top  Community Boards by Created Date'\n",
        "top_community_board_counts = rat1.groupby(['created_date', 'community_board']).size().reset_index(name='cb_count')\n",
        "\n",
        "# Sort the data by 'year' in ascending order and 'count' in descending order\n",
        "top_community_board_sorted = top_community_board_counts.sort_values(by=['created_date', 'cb_count'], ascending=[False, False])\n",
        "\n",
        "print(\"Top Addresses by Sightings Created Date:\")\n",
        "print(top_community_board_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the 'cd_count' values that are >= 5\n",
        "top_cb_greaterthan5 = top_community_board_sorted[top_community_board_sorted['cb_count'] >= 5]\n",
        "\n",
        "print(\"Top Addresses by Sightings Created Date (Counts >= 5):\")\n",
        "print(top_cb_greaterthan5)"
      ],
      "metadata": {
        "id": "u4RBp5ZptJ1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the data for cb_count >= 5\n",
        "df_filtered_counts = top_community_board_sorted[top_community_board_sorted['cb_count'] >= 5]\n",
        "\n",
        "# Get the unique cb_count values along with the community_board column\n",
        "filtered_counts = df_filtered_counts[['community_board', 'cb_count']].drop_duplicates()\n",
        "\n",
        "print(\"Top Community Boards by Sightings Created Date (Counts >= 5):\")\n",
        "print(filtered_counts)\n",
        "\n",
        "# Convert the 'created_date' column to a period type representing month and year\n",
        "top_community_board_sorted['created_date'] = pd.to_datetime(top_community_board_sorted['created_date'])\n",
        "top_community_board_sorted['month_year'] = top_community_board_sorted['created_date'].dt.to_period('M')\n",
        "\n",
        "# Filter the data for the last 5 years\n",
        "current_year_cb = pd.to_datetime('today').year\n",
        "five_years_ago_cb = current_year_cb - 5\n",
        "top_community_board_sorted_filtered = top_community_board_sorted[top_community_board_sorted['created_date'].dt.year >= five_years_ago_cb]\n",
        "\n",
        "# Filter the data for cb_count >= 5\n",
        "df_filtered_counts_filtered = top_community_board_sorted_filtered[top_community_board_sorted_filtered['cb_count'] >= 5]\n",
        "\n",
        "# Get the unique cb_count values along with the community_board column\n",
        "filtered_counts_filtered = df_filtered_counts_filtered[['community_board', 'cb_count']].drop_duplicates()\n",
        "\n",
        "print(\"Top Community Boards by Sightings Created Date (Counts >= 5, Last 5 Years):\")\n",
        "print(filtered_counts_filtered)"
      ],
      "metadata": {
        "id": "evnLwTsPrmGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the data by 'cb_count' in descending order\n",
        "filtered_counts_sorted = filtered_counts.sort_values('cb_count', ascending=False)\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the data as a bar chart\n",
        "ax.bar(filtered_counts_sorted['community_board'], filtered_counts_sorted['cb_count'])\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_xlabel('Community Board')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Top Addresses by Sightings Created Date (Counts >= 5)')\n",
        "\n",
        "# Rotate the x-axis labels for better readability (optional)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NdUWvNpH50tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yupDPs3YWGLl"
      },
      "source": [
        "#####Top Community board YQMweekday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ed8GxphdBmG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Top Community Boards by year','quarter','month','weekday'\n",
        "# top_cb_yqmw = rat1.groupby(['year','quarter','month','weekday', 'community_board'])['unique_key'].apply(lambda x: x.value_counts().idxmax())\n",
        "\n",
        "# print(\"Top Community Boards by year','quarter','month','weekday':\")\n",
        "# print(top_cb_yqmw)\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdoEbv3bWRTl"
      },
      "source": [
        "#####Top Community board YQM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSzEhVsQdBmH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Top  Community Boards by year','quarter','month'\n",
        "# top_cb_yqm = rat1.groupby(['year','quarter','month', 'community_board'])['unique_key'].apply(lambda x: x.value_counts().idxmax())\n",
        "\n",
        "# print(\"Top  Community Boards by year...:\")\n",
        "# print(top_cb_yqm)\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8lg1dbRWUbk"
      },
      "source": [
        "#####Top Community board YQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7t3fUVbdBmI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Top  Community Boards by year','quarter'\n",
        "top_cb_yq_counts = rat1.groupby(['year','quarter', 'community_board']).size().reset_index(name='yq_count')\n",
        "\n",
        "# Sort the data by 'year' in ascending order and 'count' in descending order\n",
        "top_cb_yq_sorted = top_cb_yq_counts.sort_values(by=['year','quarter', 'yq_count'], ascending=[True,True, False])\n",
        "\n",
        "print(\"Top  Community Boards by year and quarter:\")\n",
        "print(top_cb_yq_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjdeGlskWXbC"
      },
      "source": [
        "#####Top Community board Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Z8uxlwdBmI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute the count of sightings by 'year' and 'community_board'\n",
        "top_cb_y_counts = rat1.groupby(['year', 'community_board']).size().reset_index(name='y_count')\n",
        "\n",
        "# Sort the data by 'year' in ascending order and 'count' in descending order\n",
        "top_cb_y_sorted = top_cb_y_counts.sort_values(by=['year', 'y_count'], ascending=[True, False])\n",
        "\n",
        "print(\"Top incident address by year and community board:\")\n",
        "print(top_cb_y_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Eol_jqs3AN16"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co55wmniWicB"
      },
      "source": [
        "####Top Incidents by  New Columns = CB_address_zip = community board + address + zip AND CB_counts = rat1.groupby(['created_date', 'CB_address_zip'])['unique_key'].transform('count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-giwQWJcO3My"
      },
      "source": [
        "#####Year, created date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEmQmfjm_JqS"
      },
      "outputs": [],
      "source": [
        "# Create a new column combining 'community_board', 'incident_address', and 'incident_zip'\n",
        "rat1['CB_address_zip'] = rat1['community_board'] + ', ' + rat1['incident_address'] + ', ' + rat1['incident_zips']\n",
        "\n",
        "rat1['CB_counts'] = rat1.groupby(['created_date', 'CB_address_zip'])['unique_key'].transform('count')\n",
        "\n",
        "# Filter the data for the last 5 years\n",
        "current_year_cb = pd.to_datetime('today').year\n",
        "five_years_ago_cb = current_year_cb - 5\n",
        "rat1_last5yrs = rat1[rat1['created_date'].dt.year >= five_years_ago_cb]\n",
        "\n",
        "# Get the sum of the counts CB_address_zip column\n",
        "last5yrs_filtered_counts = rat1_last5yrs.groupby('CB_address_zip').agg({'CB_counts': 'sum'}).reset_index()\n",
        "top_5_address_counts = last5yrs_filtered_counts.nlargest(5, 'CB_counts')\n",
        "\n",
        "print(\"Top Addresses by Sightings Created Date (Last 5 Years):\")\n",
        "print(top_5_address_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htNFw0vURp3o"
      },
      "source": [
        "#####year quarter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRGVvVM3Qmeg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Group the data by 'year', 'quarter', and 'CB_address_zip' and calculate the count of sightings\n",
        "top_addresses_zip_yq_counts = rat1.groupby(['year', 'quarter', 'CB_address_zip']).size().reset_index(name='count_yq')\n",
        "\n",
        "# Sort the data by 'year' in descending order while keeping the years sorted alphabetically\n",
        "top_addresses_zip_yq_sorted = top_addresses_zip_yq_counts.sort_values(by=['year','quarter', 'count_yq'], ascending=[True,True, False])\n",
        "\n",
        "# Display the count of sightings by 'year', 'created_date', and 'CB_address_zip' in descending order with sorted years\n",
        "print(\"Count of sightings by 'year', 'quarter', and 'CB_address_zip' (descending order with sorted years):\")\n",
        "print(top_addresses_zip_yq_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94KrOZsCRvey"
      },
      "source": [
        "#####year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b99vXnIWaZKt"
      },
      "outputs": [],
      "source": [
        "# Group the data by 'year' and 'CB_address_zip' and calculate the count of sightings\n",
        "top_addresses_zip_y_counts = rat1.groupby(['year', 'CB_address_zip']).size().reset_index(name='count_y')\n",
        "\n",
        "# Sort the data by 'year' in descending order while keeping the years sorted alphabetically\n",
        "top_addresses_zip_y_sorted = top_addresses_zip_y_counts.sort_values(by=['year', 'count_y'], ascending=[False, False])\n",
        "\n",
        "# Select the top addresses with the highest counts for each year\n",
        "top_2_addresses = top_addresses_zip_y_sorted.groupby('year').apply(lambda x: x.nlargest(2, 'count_y')).reset_index(drop=True)\n",
        "\n",
        "# Combine 'CB_address_zip' and 'year' into a new column\n",
        "top_2_addresses['label'] = top_2_addresses['CB_address_zip'] + ' (' + top_addresses['year'].astype(str) + ')'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above looks correct...?"
      ],
      "metadata": {
        "id": "xC9naIl3b4Os"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Pi6Q7WW55l"
      },
      "outputs": [],
      "source": [
        "# Plot the counts of the top addresses with green color bars\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=top_addresses, x='count_y', y='label', color='green')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('CB_address_zip (Year)')\n",
        "plt.title('Top 2 Addresses by Community Board in each year')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by 'year' and 'CB_address_zip' and get the count\n",
        "CB_year_counts = rat1.groupby(['year', 'CB_address_zip']).size().reset_index(name='count')\n",
        "\n",
        "# Select the top addresses with the highest counts\n",
        "top_addresses = CB_year_counts.groupby('year').apply(lambda x: x.nlargest(2, 'count')).reset_index(drop=True)\n",
        "\n",
        "# Combine 'CB_address_zip' and 'year' into a new column\n",
        "top_addresses['label'] = top_addresses['CB_address_zip'] + ' (' + top_addresses['year'].astype(str) + ')'\n",
        "\n",
        "# Plot the counts of the top addresses with green color bars\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=top_addresses, x='label', y='count', color='green')\n",
        "plt.xlabel('CB_address_zip (Year)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 2 CB_address_zip with Year')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "huos76AOVbaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEryEWK6R7eR"
      },
      "source": [
        "####Top unique addresses using only incident_address"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk4Sz7gNYhwu"
      },
      "outputs": [],
      "source": [
        "top_10_unique_addresses = rat1['incident_address'].value_counts().nlargest(10).index.tolist()\n",
        "print(top_10_unique_addresses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOhb4B7U7EJ"
      },
      "source": [
        "#####Attempt this on the sets... or limit by year and community board?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3f9TNa1oS6K"
      },
      "outputs": [],
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Plot the top_addresses_by_created_date\n",
        "plt.subplot(2, 3, 1)\n",
        "top_addresses_by_created_date.plot(kind='line')\n",
        "plt.xlabel('Created Date')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Created Date')\n",
        "plt.xticks(rotation=90)\n",
        "# Plot the top_addresses_by_year\n",
        "plt.subplot(2, 3, 2)\n",
        "top_addresses_by_year.plot(kind='line')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Year')\n",
        "plt.xticks(rotation=90)\n",
        "# Plot the Top Incident Addresses codes by quarter\n",
        "plt.subplot(2, 3, 3)\n",
        "top_addresses_by_quarter.plot(kind='bar')\n",
        "plt.xlabel('Quarter')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Quarter')\n",
        "plt.xticks(rotation=90)\n",
        "# Plot the Top Incident Addresses codes by month\n",
        "plt.subplot(2, 3, 4)\n",
        "top_addresses_by_month.plot(kind='line')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Month')\n",
        "plt.xticks(rotation=90)\n",
        "# Plot the Top Incident Addresses codes by weekday\n",
        "plt.subplot(2, 3, 5)\n",
        "top_addresses_by_weekday.plot(kind='line')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Weekday')\n",
        "plt.xticks(rotation=90)\n",
        "# Plot the Top Incident Addresses codes by hour\n",
        "plt.subplot(2, 3, 6)\n",
        "top_addresses_by_hour.plot(kind='line')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Addresses')\n",
        "plt.title('Top Incident Addresses Codes by Hour')\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##rat2 New DF  I maybe over doing it but this is for my reference"
      ],
      "metadata": {
        "id": "OPCzzydrDBd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of largest values to consider\n",
        "n_largest = 3\n",
        "\n",
        "# Group the data by 'year' and 'location_type'\n",
        "year_location_type_grouped_data = rat1.groupby(['year', 'location_type'])\n",
        "\n",
        "# Sort the groups based on 'location_type' in descending order\n",
        "year_location_type_grouped_data = sorted(year_location_type_grouped_data, key=lambda x: x[0][1], reverse=True)\n",
        "\n",
        "# Define an empty dataframe to store the calculated results\n",
        "calculated_data = pd.DataFrame(columns=['year', 'location_type', 'sum_sightings_count', 'average_sightings_per_capita',\n",
        "                                        'average_duration', 'average_frequency_cb', 'create_dates_min', 'create_dates_max',\n",
        "                                        'close_dates_min', 'close_dates_max'])\n",
        "\n",
        "for year_location_type_group, group_data in year_location_type_grouped_data:\n",
        "    # Calculate sum, average, and min-max for specific columns\n",
        "    sum_sightings_count = group_data['sightings_count'].sum()\n",
        "    average_sightings_per_capita = group_data['sightings_per_capita'].mean()\n",
        "    average_duration = group_data['duration'].mean()\n",
        "    average_frequency_cb = group_data['frequency_cb'].mean()\n",
        "    create_dates_min = group_data['create_date'].min()\n",
        "    create_dates_max = group_data['create_date'].max()\n",
        "    close_dates_min = group_data['closed_date'].min()\n",
        "    close_dates_max = group_data['closed_date'].max()\n",
        "\n",
        "    # Create a new row with the calculated values\n",
        "    new_row = {'year': year_location_type_group[0],\n",
        "               'location_type': year_location_type_group[1],\n",
        "               'sum_sightings_count': sum_sightings_count,\n",
        "               'average_sightings_per_capita': average_sightings_per_capita,\n",
        "               'average_duration': average_duration,\n",
        "               'average_frequency_cb': average_frequency_cb,\n",
        "               'create_dates_min': create_dates_min,\n",
        "               'create_dates_max': create_dates_max,\n",
        "               'close_dates_min': close_dates_min,\n",
        "               'close_dates_max': close_dates_max}\n",
        "\n",
        "    # Append the new row to the calculated_data dataframe\n",
        "    calculated_data = calculated_data.append(new_row, ignore_index=True)\n",
        "\n",
        "# Merge the calculated_data dataframe with the rat2 dataframe based on 'year' and 'location_type'\n",
        "rat2 = pd.merge(rat2, calculated_data, on=['year', 'location_type'], how='left')\n"
      ],
      "metadata": {
        "id": "F9p7HDaC4101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat2"
      ],
      "metadata": {
        "id": "cjeguuip5kf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#rat2_analysis DF includes outliers"
      ],
      "metadata": {
        "id": "p9yEsbh49xNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rat2_analysis = rat1.copy()"
      ],
      "metadata": {
        "id": "F5bsadEpeUPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Top value counts by address zip :  Rat2_analysis"
      ],
      "metadata": {
        "id": "WUeJTAZqhGNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_counts = rat2_analysis.groupby('address_zip').agg({\n",
        "    'unique_key':'count',\n",
        "    'sightings_per_capita': 'mean',\n",
        "    'location_type': 'first',\n",
        "    'created_date': lambda x: list(x),\n",
        "    'city': 'first',\n",
        "    'community_board': 'first',\n",
        "    'the_geom': 'first',\n",
        "    'duration': 'mean'\n",
        "})\n",
        "\n",
        "top_counts_df = top_counts.reset_index().sort_values(['sightings_per_capita', 'unique_key'], ascending=[False, False])\n",
        "\n",
        "# Filter the DataFrame based on the 'unique_key' column\n",
        "top_counts_df = top_counts_df[top_counts_df['unique_key'] == 16]\n",
        "\n",
        "print(top_counts_df)"
      ],
      "metadata": {
        "id": "nivk6CsGd0ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sightings_per_count = rat2_analysis.groupby('address_zip').agg({\n",
        "    'unique_key':'count',\n",
        "    'sightings_per_capita': 'mean',\n",
        "    'location_type': 'first',\n",
        "    'created_date': lambda x: list(x),\n",
        "    'city': 'first',\n",
        "    'community_board': 'first',\n",
        "    'the_geom': 'first',\n",
        "    'duration': 'mean'\n",
        "}).nlargest(100, 'unique_key', keep='first')\n",
        "\n",
        "top_counts_df = top_counts.reset_index().sort_values('sightings_per_capita', ascending=False)\n",
        "print(top_counts_df)"
      ],
      "metadata": {
        "id": "ouSKZQB_HBRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_16_df = top_counts_df[top_counts_df['unique_key'] == 16]\n",
        "unique_address_zips = count_16_df['address_zip'].unique()\n",
        "print(unique_address_zips)"
      ],
      "metadata": {
        "id": "XbX7jc8CvpFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSLbCmUMTdSR"
      },
      "outputs": [],
      "source": [
        "sightings_per_capita = rat2_analysis.groupby('address_zip').agg({\n",
        "    'sightings_per_capita': 'mean',\n",
        "    'location_type': 'first',\n",
        "    'created_date': lambda x: list(x),\n",
        "    'city': 'first',\n",
        "    'community_board': 'first',\n",
        "    'the_geom': 'first',\n",
        "    'duration': 'mean'\n",
        "})\n",
        "\n",
        "sightings_per_capita['unique_key_count'] = rat2_analysis.groupby('address_zip')['unique_key'].count()\n",
        "sightings_per_capita_df = sightings_per_capita.reset_index().sort_values('sightings_per_capita', ascending=False)\n",
        "print(sightings_per_capita_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sightings_per_capita_df.unique_key_count.unique()"
      ],
      "metadata": {
        "id": "EKakHJhK9I9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this needs fixed"
      ],
      "metadata": {
        "id": "CGSAT3Xn34zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accumulated count per location type\n",
        "accumulated_count = sightings_per_capita_df.groupby('location_type')['unique_key_count'].sum().reset_index()\n",
        "top_5_location_types = accumulated_count.nlargest(5, 'unique_key_count')['location_type']\n",
        "\n",
        "# Filter the data for the top 5 location types\n",
        "top_5_per_category = (\n",
        "    sightings_per_capita_df[sightings_per_capita_df['location_type'].isin(top_5_location_types)]\n",
        "    .groupby('location_type')\n",
        "    .apply(lambda x: x.nlargest(2, 'unique_key_count'))\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Sort the location types in descending order based on the accumulated count\n",
        "top_5_per_category = top_5_per_category.sort_values('unique_key_count', ascending=False)\n",
        "\n",
        "# Plot the filtered data\n",
        "sns.catplot(y='location_type', hue='community_board', data=top_5_per_category, kind='count', height=16, aspect=1.5)"
      ],
      "metadata": {
        "id": "7SgYOnLWCMuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the series to a DataFrame\n",
        "normalized_top_addresses = pd.DataFrame(top_addresses_by_created_date)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "normalized_top_addresses.reset_index(inplace=True)\n",
        "\n",
        "# Rename the columns\n",
        "normalized_top_addresses.columns = ['created_date', 'address_zip', 'count']\n",
        "\n",
        "# Convert the 'created_date' column to a period type representing month and year\n",
        "normalized_top_addresses['created_date'] = pd.to_datetime(normalized_top_addresses['created_date'])\n",
        "normalized_top_addresses['month_year'] = normalized_top_addresses['created_date'].dt.to_period('M')\n",
        "\n",
        "# Filter the data for the last 5 years\n",
        "current_year = pd.to_datetime('today').year\n",
        "five_years_ago = current_year - 5\n",
        "normalized_top_addresses = normalized_top_addresses[normalized_top_addresses['created_date'].dt.year >= five_years_ago]\n",
        "\n",
        "# Get the top 3 ZIP codes per month\n",
        "top_3_per_month = normalized_top_addresses.groupby('month_year').apply(lambda x: x.nlargest(1, 'count')).reset_index(drop=True)\n",
        "\n",
        "# Create a figure and axes with a wider plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot the data\n",
        "top_3_per_month.groupby('month_year').apply(lambda x: plt.bar(x['address_zip'], x['count'], alpha=0.7))\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_xlabel('ZIP Code')\n",
        "ax.set_ylabel('Sightings per Capita')\n",
        "ax.set_title('Top Addresses ZIP Codes per Month (Last 5 Years) - Normalized')\n",
        "\n",
        "# Rotate the x-axis labels for better readability (optional)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fsNwDyKMZTRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.barplot(x='address_zip', y='sightings_per_capita', hue='community_board', data=top_100_address_counts_df)\n",
        "# plt.xlabel('address_zip')\n",
        "# plt.ylabel('sightings_per_capita')\n",
        "# plt.title('Comparison of Counts')\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "zksYKZbP1RTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlJZy2NCWkbM"
      },
      "source": [
        "#rat1_analysis: NEW df with no no nulls/ for value counts to scale and analyse/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUrFoPe0VVUH"
      },
      "outputs": [],
      "source": [
        "# Create a new DataFrame for rat1 analysis\n",
        "rat1_analysis = rat1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the specified columns\n",
        "columns_to_drop = ['incident_address','incident_zip', 'incident_zips','cross_street _1', 'cross_street_2','closed_date','due_date', 'intersection_street_1', 'intersection_street_2', 'address_Type', 'landmark', 'X Coordinate (State Plane)',\n",
        "       'Y Coordinate (State Plane)', 'latitude', 'longitude', 'location','table_count', 'modztca', 'label', 'zcta', 'pop_est', 'create_date', 'close_date', 'frequency_cb']\n",
        "rat1_analysis = rat1_analysis.drop(columns_to_drop, axis=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "znMY-_JZ6ZR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##rat1_analysis DF without outliers  for ml"
      ],
      "metadata": {
        "id": "AvQAJeNaej8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = rat1_analysis['frequency_cb'].quantile(0.25)\n",
        "Q3 = rat1_analysis['frequency_cb'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = rat1_analysis[(rat1_analysis['frequency_cb'] < lower_bound) | (rat1_analysis['frequency_cb'] > upper_bound)]"
      ],
      "metadata": {
        "id": "Xcg5SaqseqGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1_analysis = rat1_analysis[~((rat1_analysis['frequency_cb'] < lower_bound) | (rat1_analysis['frequency_cb'] > upper_bound))]"
      ],
      "metadata": {
        "id": "38iACF90f78p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcfPlFBJLwq4"
      },
      "outputs": [],
      "source": [
        "rat1_analysis.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqm748VDegqn"
      },
      "outputs": [],
      "source": [
        "# sns.heatmap(rat1_analysis.isnull(), cbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAjnYn7oHSL8"
      },
      "outputs": [],
      "source": [
        "missing_counts =   rat1_analysis.isnull().sum().sort_values(ascending = False)\n",
        "percent = ( rat1_analysis.isnull().sum()*100/  rat1_analysis.shape[0]).sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luI4_TKyQQl8"
      },
      "outputs": [],
      "source": [
        "missing_rat1 = pd.concat([missing_counts, percent], axis = 1, keys = ['Counts', '%'])\n",
        "print(f' Missing values: \\n{missing_rat1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5737woyPhx5w"
      },
      "outputs": [],
      "source": [
        "rat1_analysis.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDrWcMLPjsXl"
      },
      "outputs": [],
      "source": [
        "# Drop the specified columns\n",
        "columns_to_drop = ['incident_address','incident_zip', 'incident_zips','cross_street _1', 'cross_street_2','closed_date','due_date', 'intersection_street_1', 'intersection_street_2', 'address_Type', 'landmark', 'X Coordinate (State Plane)',\n",
        "       'Y Coordinate (State Plane)', 'latitude', 'longitude', 'location','table_count', 'modztca', 'label', 'zcta', 'pop_est', 'create_date', 'close_date', 'frequency_cb']\n",
        "rat1_analysis = rat1_analysis.drop(columns_to_drop, axis=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index and sort by 'unique_key' and 'created_date' in ascending order\n",
        "rat1_analysis_sorted = rat1_analysis.sort_values(by=['created_date','unique_key'], ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(rat1_analysis_sorted)"
      ],
      "metadata": {
        "id": "TJo0Zo2T9kSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1_analysis = rat1_analysis_sorted.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "PQUObLP_3F8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_counts_ck =   rat1_analysis.isnull().sum().sort_values(ascending = False)\n",
        "percent_ck = ( rat1_analysis.isnull().sum()*100/  rat1_analysis.shape[0]).sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "dxqM7fuxtwHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rat = pd.concat([missing_counts_ck, percent], axis = 1, keys = ['Counts', '%'])\n",
        "print(f' Missing values: \\n{missing_rat}')"
      ],
      "metadata": {
        "id": "kz0atn8XtivE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1_analysis.info()"
      ],
      "metadata": {
        "id": "zpJl6WejKeo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hzx0uxNnl4T"
      },
      "outputs": [],
      "source": [
        "# sns.heatmap(rat1_analysis.isnull(), cbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rat1_analysis['city'] = rat1_analysis['city'].fillna('UNSPECIFIED')"
      ],
      "metadata": {
        "id": "Zd_a1ENA0Tvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rat1_analysis.columns"
      ],
      "metadata": {
        "id": "fE4LOE2T0x3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###StandardScalor"
      ],
      "metadata": {
        "id": "uDxNFkUWGC0U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM-r5ZiQxT5d"
      },
      "outputs": [],
      "source": [
        "top_address_scale = top_address_counts.copy()\n",
        "\n",
        "# Select numeric columns for scaling\n",
        "numeric_columns = top_address_scale.select_dtypes(include=['int', 'float']).columns\n",
        "\n",
        "# Scale the numeric columns\n",
        "scaler = StandardScaler()\n",
        "top_address_scale[numeric_columns] = scaler.fit_transform(top_address_scale[numeric_columns])\n",
        "\n",
        "print(top_address_scale)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(address_zip)"
      ],
      "metadata": {
        "id": "Ttates73aYuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = top_address_scale.corr()\n",
        "\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={'fontsize': 10})\n",
        "plt.title('Correlation Matrix')\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzmbSrqxVpVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MinMaxScaler"
      ],
      "metadata": {
        "id": "CYMrdlnFGIZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_address_counts.isnull().sum()"
      ],
      "metadata": {
        "id": "z8-qPAYlHNlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFmqFQREBccf"
      },
      "outputs": [],
      "source": [
        "top_address_scale2 = top_address_counts.copy()\n",
        "top_address_scale2 = top_address_scale2.fillna(top_address_scale2.mean())\n",
        "\n",
        "# Define data\n",
        "data = top_address_scale2\n",
        "\n",
        "# Define min-max scaler\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "# Transform data\n",
        "scaled_top_address2 = scaler2.fit_transform(data)\n",
        "\n",
        "print(scaled_top_address2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation matrix\n",
        "minmax_correlation_matrix = np.corrcoef(scaled_top_address2, rowvar=False)\n",
        "\n",
        "print(minmax_correlation_matrix)"
      ],
      "metadata": {
        "id": "h8neihBjNFRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(minmax_correlation_matrix, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={'fontsize': 10})\n",
        "\n",
        "plt.title('Min Max - Correlation Matrix')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "guHHGhjLSrZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "because it looks pretty"
      ],
      "metadata": {
        "id": "eS9h5uFuSI4j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8c1AvfahX0SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oazeKYh3xmCO"
      },
      "source": [
        "# Exports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYdz6VKGxuTs"
      },
      "outputs": [],
      "source": [
        "# Export Selected Columns to CSV File\n",
        "#column_names = ['', '','']\n",
        "#df.to_csv(\"c:/tmp/courses.csv\",index=False, columns=column_names)\n",
        "\n",
        "# Writes Content to CSV File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMNznJMyWgs1"
      },
      "source": [
        "###Print to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p27ytF9Jnna6"
      },
      "outputs": [],
      "source": [
        "#df_top_addresses.to_csv(\"/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/outputs_pandas/df_top_addresses.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8fIdOftUj9"
      },
      "outputs": [],
      "source": [
        "#rat1.to_csv(\"/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/outputs_pandas/rat1.csv\")\n",
        "# dsny1.to_csv(\"/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/outputs_pandas/dsny1.csv\")\n",
        "#rat1_analysis.to_csv(\"/content/drive/MyDrive/Projects/rats_analysis_application/Datasources/outputs_pandas/rat1_analysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLPJ6K492UcZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# output_file_path1 = os.path.join(output_directory, 'top_25_address_counts.csv')\n",
        "# output_file_path2 = os.path.join(output_directory, 'top_address_counts.csv')\n",
        "# output_file_path3 = os.path.join(output_directory, 'top_address_scale.csv')\n",
        "\n",
        "# top_address_scale.to_csv(output_file_path3, index=False, mode='w')\n",
        "# top_25_address_counts.to_csv(output_file_path1, index=False, mode='w')\n",
        "# top_address_counts.to_csv(output_file_path2, index=False, mode='w')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WUeJTAZqhGNU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}